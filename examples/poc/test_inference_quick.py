"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯æ¨ç†ç³»ç»ŸåŸºæœ¬åŠŸèƒ½ (é€‚é…æ–°ç‰ˆæ¸è¿›å¼æ¨ç†)

æµ‹è¯•æµç¨‹:
1. åŠ è½½å°‘é‡9æœˆæ•°æ®æ„å»ºè®°å¿†
2. åœ¨2-3ä¸ª10æœˆæ ·æœ¬ä¸Šæµ‹è¯•æ¨ç†
3. è¾“å‡ºè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹
"""

import sys
import time
from pathlib import Path
from datetime import datetime

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ–°ç‰ˆå‡½æ•°
from anker_identity_inference import (
    load_data,
    add_events_to_memory,
    infer_event,
    format_timestamp,
    parse_result,
    MetricsCalculator,
    get_time_period,
)
from memos.log import get_logger

logger = get_logger(__name__)

def quick_test(
    family_id: str = "T8030P1322100087",
    train_samples: int = 5,
    val_samples: int = 5,
    test_samples: int = 3,
):
    """
    å¿«é€Ÿæµ‹è¯•æ¨ç†åŠŸèƒ½
    """
    logger.info(f"\n{'='*70}")
    logger.info(f"ğŸš€ å¿«é€Ÿæµ‹è¯• - å®¶åº­ {family_id}")
    logger.info(f"{'='*70}\n")
    
    # 1. å‡†å¤‡ç¯å¢ƒ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    user_id = f"test_{family_id}_{timestamp}"
    mem_cube_id = f"cube_test_{family_id}_{timestamp}"
    session_id = f"sess_test_{family_id}_{timestamp}"
    
    # 2. åŠ è½½æ•°æ®
    logger.info(f"ğŸ“¥ æ­¥éª¤1: åŠ è½½æ•°æ®...")
    train_all, test_all = load_data(family_id)
    
    # å‡†å¤‡è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†
    if len(train_all) <= train_samples:
        train_events = train_all
        validation_events = []
    else:
        train_events = train_all[:train_samples]
        validation_events = train_all[train_samples:train_samples + val_samples]
    
    test_events = test_all[:test_samples] if len(test_all) > test_samples else test_all
    
    logger.info(f"âœ“ é€‰å–è®­ç»ƒæ ·æœ¬: {len(train_events)} æ¡")
    logger.info(f"âœ“ é€‰å–éªŒè¯æ ·æœ¬: {len(validation_events)} æ¡")
    logger.info(f"âœ“ é€‰å–10æœˆæµ‹è¯•æ ·æœ¬: {len(test_events)} æ¡\n")
    
    # 3. æ„å»ºè®°å¿†
    logger.info(f"ğŸ”¨ æ­¥éª¤2: æ„å»ºè®°å¿† (å…± {len(train_events)} æ¡)...")
    
    # è¿™é‡Œä¸ä½¿ç”¨add_events_to_memoryçš„å†…éƒ¨è¿›åº¦æ¡ï¼Œè€Œæ˜¯è‡ªå·±æ§åˆ¶ï¼Œå› ä¸ºæ ·æœ¬å°‘ï¼Œä¸éœ€è¦å¤ªå¤æ‚
    total_add_time = 0
    from memos.api.product_models import APIADDRequest
    from memos.api.routers.server_router import add_memories
    
    for i, event in enumerate(train_events, 1):
        start_t = time.time()
        
        # å†…å®¹å¢å¼º
        ts = event.get('timestamp', '')
        enhanced_content = f"""[Security Log]
Time: {format_timestamp(ts)} ({get_time_period(ts)})
Observation: {event['original_description']}

Note: Extract key visual features (clothes, colors), vehicle details, and behavioral patterns to aid future identity re-identification."""

        add_req = APIADDRequest(
            user_id=user_id,
            mem_cube_id=mem_cube_id,
            messages=[{"role": "user", "content": enhanced_content}],
            session_id=session_id,
            source="anker_security"
        )
        try:
            add_memories(add_req)
            elapsed = time.time() - start_t
            total_add_time += elapsed
            
            # æ˜¾ç¤ºè¿›åº¦
            avg_time = total_add_time / i
            remaining = (len(train_events) - i) * avg_time
            # ç®€å•çš„è¿›åº¦æ¡ [====>....]
            bar_len = 20
            filled = int(i / len(train_events) * bar_len)
            bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
            
            sys.stdout.write(f"\r    [{bar}] {i}/{len(train_events)} | æœ¬æ¬¡:{elapsed:.2f}s | å¹³å‡:{avg_time:.2f}s | å‰©:{remaining:.0f}s")
            sys.stdout.flush()
            
        except Exception as e:
            logger.error(f"\nâŒ Error adding event {i}: {e}")
            
    sys.stdout.write(f"\n    âœ… è®°å¿†æ„å»ºå®Œæˆ! æ€»è€—æ—¶: {total_add_time:.1f}s\n\n")
    
    # 4. éªŒè¯é›†å‡†ç¡®ç‡ (åŸºäº9æœˆæœ‰æ ‡æ³¨æ•°æ®)
    if validation_events:
        logger.info(f"ğŸ“Š æ­¥éª¤3: åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡ ({len(validation_events)} æ¡)...")
        predictions = []
        ground_truth = {}
        
        for idx, event in enumerate(validation_events, 1):
            role, sub, conf, raw = infer_event(event, user_id, mem_cube_id)
            predictions.append({
                "video_path": event["video_path"],
                "predicted_role_type": role,
                "predicted_sub_role_type": sub,
                "confidence": conf,
            })
            ground_truth[event["video_path"]] = {
                "role_type": event["role_type"],
                "sub_role_type": event["sub_role_type"],
            }
        
        metrics = MetricsCalculator.calculate(predictions, ground_truth)
        logger.info("   âœ… éªŒè¯ç»“æœ:")
        logger.info(f"     - èº«ä»½å¤§ç±»å‡†ç¡®ç‡: {metrics['role_acc']*100:.1f}%")
        logger.info(f"     - èº«ä»½å­ç±»å‡†ç¡®ç‡: {metrics['sub_role_acc']*100:.1f}%")
        logger.info(f"     - å®¶äººè¯†åˆ«å‡†ç¡®ç‡: {metrics['family_acc']*100:.1f}%")
        logger.info(f"     - å¼‚å¸¸æ£€æµ‹å‡†ç¡®ç‡: {metrics['anomaly_acc']*100:.1f}%\n")
    else:
        logger.info("âš ï¸ éªŒè¯é›†ä¸ºç©ºï¼Œè·³è¿‡å‡†ç¡®ç‡è¯„ä¼°\n")
    
    # 5. 10æœˆæ¨ç†ç¤ºä¾‹
    logger.info(f"ğŸ” æ­¥éª¤4: å¼€å§‹10æœˆæ¨ç†ç¤ºä¾‹ ({len(test_events)} æ¡)...\n")
    
    results = []
    total_inference_time = 0
    
    for idx, event in enumerate(test_events, 1):
        logger.info(f"{'â”€'*70}")
        logger.info(f"ğŸ”„ æµ‹è¯•æ ·æœ¬ {idx}/{len(test_events)}")
        logger.info(f"{'â”€'*70}")
        logger.info(f"ğŸ“… æ—¶é—´: {format_timestamp(event['timestamp'])}")
        logger.info(f"ğŸ“ æè¿°: {event['original_description'][:100]}...")
        logger.info(f"\nâš¡ æ­£åœ¨æ¨ç†...")
        
        start_t = time.time()
        # è°ƒç”¨æ–°ç‰ˆæ¨ç†å‡½æ•°
        role, sub, conf, raw = infer_event(event, user_id, mem_cube_id)
        cost = time.time() - start_t
        total_inference_time += cost
        
        logger.info(f"\nğŸ“¤ æ¨ç†ç»“æœ:")
        logger.info(f"  â€¢ èº«ä»½å¤§ç±»: {role}")
        logger.info(f"  â€¢ èº«ä»½å­ç±»: {sub}")
        logger.info(f"  â€¢ ç½®ä¿¡åº¦: {conf}")
        logger.info(f"  â€¢ è€—æ—¶: {cost:.2f}s")
        
        logger.info(f"\nğŸ’¬ å®Œæ•´æ¨ç†å“åº”:")
        preview = raw[:500] + "..." if len(raw) > 500 else raw
        logger.info(f"  {preview}")
        
        results.append({
            "sample_num": idx,
            "role": role,
            "sub": sub,
            "conf": conf
        })
        
        logger.info(f"{'â”€'*70}\n")
    
    # æ€»ç»“
    logger.info(f"{'='*70}")
    logger.info(f"âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
    if results:
        avg_time = total_inference_time / len(results)
        logger.info(f"â±ï¸  å¹³å‡æ¨ç†è€—æ—¶: {avg_time:.2f}s")
    logger.info(f"{'='*70}\n")
    
    return results

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--family", type=str, default="T8030P1322100087")
    parser.add_argument("--train-samples", type=int, default=5)
    parser.add_argument("--val-samples", type=int, default=5)
    parser.add_argument("--test-samples", type=int, default=3)
    args = parser.parse_args()
    
    try:
        quick_test(args.family, args.train_samples, args.val_samples, args.test_samples)
        
        # ä¿®å¤: ç»™åå°çº¿ç¨‹æ›´å¤šæ—¶é—´å®Œæˆæ”¶å°¾å·¥ä½œï¼Œé¿å… "interpreter shutdown" é”™è¯¯
        # MemOS çš„åå°ä»»åŠ¡(è®°å¿†æ•´ç†)æ˜¯å¼‚æ­¥çš„ï¼Œå¦‚æœè„šæœ¬é€€å‡ºå¤ªå¿«ï¼Œä¼šå¯¼è‡´çº¿ç¨‹æ± å…³é—­é”™è¯¯
        logger.info("â³ ç­‰å¾…ç³»ç»Ÿåå°ä»»åŠ¡æ¸…ç† (çº¦10ç§’)...")
        time.sleep(10) 
        logger.info("ğŸ‘‹ é€€å‡ºç¨‹åº")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
